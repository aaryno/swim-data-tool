# v0.2.0 - Import Commands Implementation Plan

**Goal:** Implement swimmer data import from USA Swimming API

**Status:** Planning → In Progress

---

## Features to Implement

### 1. USA Swimming API Client (Real Integration)

Currently we have a stub API client. Need to implement actual API calls.

**Research needed:**
- USA Swimming Times Search API endpoints
- Authentication requirements (if any)
- Rate limiting
- Response formats

**Key endpoints to implement:**
- Team swimmer search
- Individual swimmer career history
- Meet results by date range

### 2. Import Swimmers Command

```bash
swim-data-tool import swimmers --src=usa-swimming [--start-date=YYYY-MM-DD] [--end-date=YYYY-MM-DD]
```

**Features:**
- Read team codes from .env
- Query USA Swimming for all team swimmers
- Download individual career data
- Save to `data/raw/swimmers/<swimmer-name>.csv`
- Progress tracking with rich progress bars
- Resumability (skip already downloaded)
- Error handling and retry logic

### 3. Import Swimmer Command (Single)

```bash
swim-data-tool import swimmer "First Last" [--full] [--start-date] [--end-date]
```

**Features:**
- Search for specific swimmer
- Download career data
- `--full` flag for all swims (not just team-affiliated)
- Update existing CSV if already present

### 4. Data Models

Need models for:
- Swimmer (PersonKey, name, DOB, etc.)
- Swim (event, time, meet, date, course)
- Meet (name, date, location, course)

### 5. Progress Tracking & Resumability

- Log file tracking what's been downloaded
- Check existing files before re-downloading
- Progress bar showing: X/Y swimmers, current swimmer name
- Estimated time remaining

---

## Implementation Phases

### Phase 1: Research & API Client ✅ (Starting)
- [ ] Research USA Swimming Times API
- [ ] Implement API authentication
- [ ] Implement team search endpoint
- [ ] Implement swimmer search endpoint
- [ ] Implement career history endpoint
- [ ] Add rate limiting
- [ ] Add error handling

### Phase 2: Data Models
- [ ] Create Swimmer model
- [ ] Create Swim model
- [ ] Create Meet model
- [ ] CSV serialization/deserialization
- [ ] Add tests

### Phase 3: Import Swimmers Command
- [ ] CLI command structure
- [ ] Team roster fetching
- [ ] Batch swimmer download
- [ ] Progress bars with rich
- [ ] Resumability logic
- [ ] Error recovery
- [ ] Add tests

### Phase 4: Import Swimmer Command
- [ ] CLI command structure
- [ ] Single swimmer search
- [ ] Download logic
- [ ] --full flag implementation
- [ ] Add tests

### Phase 5: Integration & Testing
- [ ] Test with real API
- [ ] Test resumability
- [ ] Test error handling
- [ ] Performance optimization
- [ ] Update documentation

---

## Technical Considerations

### USA Swimming API

From prior knowledge (ford project), the USA Swimming Times system uses:
- Base URL: https://times.usaswimming.org/
- No authentication required for basic queries
- Returns HTML that needs parsing (no JSON API)
- Rate limiting: Be respectful, add delays between requests

**Alternative approach:** Use existing working implementation from ford project as reference.

### File Organization

```
data/
├── raw/
│   └── swimmers/
│       ├── john-doe.csv
│       ├── jane-smith.csv
│       └── ...
└── logs/
    └── import-swimmers.log
```

### CSV Format

Based on ford project format:
```csv
PersonKey,PreferredName,FirstName,LastName,Age,Date,Event,Time,Course,StandardTime,Meet,LSC,Club,Stroke,Distance
```

---

## Questions to Resolve

1. Should we use the existing ford scripts as reference/starting point?
2. Do we need World Aquatics scraper for v0.2.0 or defer to later?
3. What level of error handling (retry count, backoff strategy)?
4. Should progress be saved to allow true resume across sessions?

---

**Created:** 2025-10-07  
**Target Release:** v0.2.0

